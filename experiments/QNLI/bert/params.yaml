dev_file: data/preprocessed/QNLI/dev_bert.jsonl
meta_dir: data/preprocessed/QNLI/
train_file: data/preprocessed/QNLI/train_bert.jsonl
#dev_file: data/preprocessed/SNLIdebug/dev_bert.jsonl
#meta_dir: data/preprocessed/SNLIdebug/
#train_file: data/preprocessed/SNLIdebug/train_bert.jsonl
network: bert
fix_embeddings: false
use_cuda: true
batch_size: 20
epoches: 3
optimizer: bert-adam
length_limit: 128
learning_rate: 2.0e-5
warmup_proportion: 0.1
loss_funtion: cross_entropy
model_dir: ../pytorch-pretrained-BERT/examples/output/bert-base-uncased/
vocab_file: ../pytorch-pretrained-BERT/examples/output/bert-base-uncased/vocab.txt